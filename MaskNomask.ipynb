{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
      "Requirement already satisfied: h5py in c:\\users\\kpatnaik\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\kpatnaik\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\kpatnaik\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from keras) (5.1.2)\n",
      "Collecting keras-preprocessing>=1.0.5 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\kpatnaik\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from keras) (1.3.1)\n",
      "Collecting keras-applications>=1.0.6 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\kpatnaik\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from keras) (1.16.5)\n",
      "Installing collected packages: keras-preprocessing, keras-applications, keras\n",
      "Successfully installed keras-2.3.1 keras-applications-1.0.8 keras-preprocessing-1.1.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Created on Thu Apr 25 20:22:30 2020\n",
    "@author: Kartik\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from datetime import datetime\n",
    "import geocoder\n",
    "import cv2\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from resizeimage import resizeimage\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import load_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KPATNAIk\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2206 images belonging to 2 classes.\n",
      "Found 553 images belonging to 2 classes.\n",
      "Epoch 1/25\n",
      "250/250 [==============================] - 274s 1s/step - loss: 0.3522 - accuracy: 0.8771 - val_loss: 0.0949 - val_accuracy: 0.9580\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 257s 1s/step - loss: 0.1112 - accuracy: 0.9617 - val_loss: 0.1144 - val_accuracy: 0.9530\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 243s 971ms/step - loss: 0.0816 - accuracy: 0.9715 - val_loss: 0.1029 - val_accuracy: 0.9611\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 229s 918ms/step - loss: 0.0616 - accuracy: 0.9787 - val_loss: 0.1030 - val_accuracy: 0.9703\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 260s 1s/step - loss: 0.0550 - accuracy: 0.9816 - val_loss: 0.0594 - val_accuracy: 0.9740\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 286s 1s/step - loss: 0.0563 - accuracy: 0.9825 - val_loss: 0.0647 - val_accuracy: 0.9622\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 308s 1s/step - loss: 0.0384 - accuracy: 0.9880 - val_loss: 0.0022 - val_accuracy: 0.9724\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 356s 1s/step - loss: 0.0290 - accuracy: 0.9899 - val_loss: 0.0146 - val_accuracy: 0.9775\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 355s 1s/step - loss: 0.0307 - accuracy: 0.9890 - val_loss: 0.2590 - val_accuracy: 0.9785\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 297s 1s/step - loss: 0.0222 - accuracy: 0.9932 - val_loss: 0.1981 - val_accuracy: 0.9650\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 240s 959ms/step - loss: 0.0262 - accuracy: 0.9911 - val_loss: 0.0113 - val_accuracy: 0.9755\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 229s 915ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 0.0153 - val_accuracy: 0.9826\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 227s 908ms/step - loss: 0.0255 - accuracy: 0.9919 - val_loss: 0.0416 - val_accuracy: 0.9785\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 213s 851ms/step - loss: 0.0166 - accuracy: 0.9957 - val_loss: 0.0241 - val_accuracy: 0.9880\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 212s 848ms/step - loss: 0.0160 - accuracy: 0.9952 - val_loss: 8.6828e-04 - val_accuracy: 0.9785\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 216s 866ms/step - loss: 0.0101 - accuracy: 0.9964 - val_loss: 0.2556 - val_accuracy: 0.9755\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 214s 857ms/step - loss: 0.0092 - accuracy: 0.9972 - val_loss: 0.2539 - val_accuracy: 0.9816\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 215s 860ms/step - loss: 0.0163 - accuracy: 0.9945 - val_loss: 5.2243e-04 - val_accuracy: 0.9796\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 214s 855ms/step - loss: 0.0137 - accuracy: 0.9956 - val_loss: 0.0237 - val_accuracy: 0.9710\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 214s 857ms/step - loss: 0.0105 - accuracy: 0.9971 - val_loss: 0.0469 - val_accuracy: 0.9703\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 212s 849ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 0.0096 - val_accuracy: 0.9683\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 218s 872ms/step - loss: 0.0133 - accuracy: 0.9959 - val_loss: 0.0027 - val_accuracy: 0.9765\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 212s 848ms/step - loss: 0.0087 - accuracy: 0.9967 - val_loss: 0.7440 - val_accuracy: 0.9630\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 212s 850ms/step - loss: 0.0152 - accuracy: 0.9952 - val_loss: 0.0828 - val_accuracy: 0.9734\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 222s 887ms/step - loss: 0.0144 - accuracy: 0.9959 - val_loss: 0.1391 - val_accuracy: 0.9724\n"
     ]
    }
   ],
   "source": [
    "# Initialising the CNN\n",
    "classifier = Sequential() #object of class sequential.\n",
    "\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Convolution2D(32, (3, 3), input_shape = (160, 160, 3), activation = 'relu'))\n",
    "#(32-no of filters/feature map, no of rows & col of feature detector matrix,I_shape=3-no of channel\n",
    "#colour image, 64*64 format for image converstion, )\n",
    "\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "# to reduce no. of nodes in flattening, 2,2 to size the mat that slides over.\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Convolution2D(32, 3, 3, activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(activation=\"relu\", units=128)) #rectifier A FN for input/hidden layer.\n",
    "classifier.add(Dense(activation=\"sigmoid\", units=1)) #sigmoid layer.\n",
    "\n",
    "#classifier.add(Dense())\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Part 2 - Fitting the CNN to the images\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('C:/Users/KPATNAIk/Desktop/mask/dataset/training_set',\n",
    "                                                 target_size = (160, 160),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('C:/Users/KPATNAIk/Desktop/mask/dataset/test_set',\n",
    "                                            target_size = (160, 160),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "\n",
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = 250,\n",
    "                         epochs = 25,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 32)\n",
    "\n",
    "\n",
    "classifier.save('C:/Users/KPATNAIk/Desktop/mask/mask.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Apr 23 22:00:03 2020\n",
    "@author: Abhishek\n",
    "\"\"\"\n",
    "\n",
    "g = geocoder.ip('me')\n",
    "a=str(g.latlng[0])\n",
    "b=str(g.latlng[1])\n",
    "c='GPS::'+a+' '+b\n",
    "\n",
    "detector = MTCNN()\n",
    "\n",
    "model = load_model(\"C:/Users/KPATNAIk/Desktop/mask/mask.h5\")\n",
    "\n",
    "\n",
    "font = cv2.FONT_HERSHEY_TRIPLEX\n",
    "font2 = cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
    "font3 = cv2.FONT_HERSHEY_SCRIPT_COMPLEX\n",
    "font4 = cv2.FONT_HERSHEY_SIMPLEX\n",
    "#image_file = load_img('test_img.jpg')\n",
    "\n",
    "#print(chr(169))\n",
    "#rights=chr(169)+'2020'\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True: \n",
    "    \n",
    "    #Capture frame-by-frame\n",
    "    __, frame = cap.read()\n",
    "    \n",
    "    cv2.putText(frame,str(datetime.now()),(10,30), font3, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "    cv2.putText(frame,c,(10,450), font2, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "    cv2.putText(frame,'Kartik\\'s CAM',(480,450), font2, 0.9,(255,255,255),2,cv2.LINE_AA)\n",
    "    #Use MTCNN to detect faces\n",
    "    result = detector.detect_faces(frame)\n",
    "    if result != []:\n",
    "        for person in result:\n",
    "            bounding_box = person['box']\n",
    "            keypoints = person['keypoints']\n",
    "            #cv2.putText(frame,\"The Face\",(200,100), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "            cv2.imwrite('opencv.png', frame)\n",
    "            image_file = load_img('opencv.png')\n",
    "            cover = resizeimage.resize_cover(image_file, [160, 160], validate=False)\n",
    "\n",
    "\n",
    "            x = []\n",
    "            \n",
    "            \n",
    "            x = img_to_array(cover)\n",
    "            \n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            \n",
    "            pred = model.predict(x)\n",
    "            \n",
    "            #print(pred[0][0])\n",
    "            \n",
    "            if pred[0][0]==0.0:\n",
    "                cv2.putText(frame,\"ACCESS GRANTED, MASK ON\",(100,100), font4, 0.8,(0,255,0),2,cv2.LINE_AA)\n",
    "            \n",
    "            elif pred[0][0]==1.0:\n",
    "                cv2.putText(frame,\"ACCESS DENIED, No FACE-MASK\",(100,100), font4, 0.8,(0,0,255),2,cv2.LINE_AA)\n",
    "            \n",
    "            cv2.rectangle(frame,\n",
    "                          (bounding_box[0], bounding_box[1]),\n",
    "                          (bounding_box[0]+bounding_box[2], bounding_box[1] + bounding_box[3]),\n",
    "                          (0,155,255),\n",
    "                          2)\n",
    "    \n",
    "            cv2.circle(frame,(keypoints['left_eye']), 2, (0,155,255), 2)\n",
    "            cv2.circle(frame,(keypoints['right_eye']), 2, (0,155,255), 2)\n",
    "            cv2.circle(frame,(keypoints['nose']), 2, (0,155,255), 2)\n",
    "            cv2.circle(frame,(keypoints['mouth_left']), 2, (0,155,255), 2)\n",
    "            cv2.circle(frame,(keypoints['mouth_right']), 2, (0,155,255), 2)\n",
    "    #display resulting frame\n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(10) &0xFF == ord('q'):\n",
    "        break\n",
    "#When everything's done, release capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
